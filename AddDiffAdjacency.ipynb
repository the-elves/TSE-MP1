{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "import pydot\n",
    "import networkx as nx\n",
    "from parse import tokenizer\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from networkx.drawing.nx_pydot import from_pydot\n",
    "import numpy as np\n",
    "import json\n",
    "MAX_NODES=500\n",
    "\n",
    "after_fn = \"/home/ajinkya/TSE/mp1/joern-parse-output/after/graphs.dot\"\n",
    "\n",
    "def get_next_graph(fn):\n",
    "    graph_lines=[]\n",
    "    with open(fn) as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if line is None: \n",
    "                break\n",
    "#             if line.startswith('digraph'):\n",
    "#                 line = line.replace(\":\", \"_\").replace('~', \"_\")\n",
    "            if line == \"\\n\":\n",
    "                graph = ''.join(graph_lines)\n",
    "                graph_lines=[]\n",
    "                yield graph\n",
    "            else:\n",
    "                graph_lines.append(line)\n",
    "model = KeyedVectors.load_word2vec_format('w2v.model.txt', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('function_name_to_graph') as f:\n",
    "#     funtion_name_to_graph = pickle.load(f)\n",
    "\n",
    "def check_node_with_label_exist(fname, label):\n",
    "    g = function_name_to_graph[fname]\n",
    "    #iterate over before veritces\n",
    "    for v in g[0]:\n",
    "        if label in v[1]:\n",
    "            return True\n",
    "    return False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'nsc_rle_decode', 'astParentFullName': '', 'columnNumberEnd': 0, 'fullName': 'nsc_rle_decode', 'signature': 'static void nsc_rle_decode (BYTE *,BYTE *,UINT32)', 'astParentType': '', 'columnNumber': 0, 'lineNumberEnd': 139, '_label': 'METHOD', 'code': 'nsc_rle_decode (BYTE* in,BYTE* out,UINT32 originalSize)', 'isExternal': False, 'lineNumber': 95, 'id': 2743054800571798583, 'order': -1, 'filename': '/home/ajinkya/TSE/mp1/files/before/nsc.c', 'source': '{\\n\\tUINT32 len;\\n\\tUINT32 left;\\n\\tBYTE value;\\n\\tleft = originalSize;\\n\\n\\twhile (left > 4)\\n\\t{\\n\\t\\tvalue = *in++;\\n\\n\\t\\tif (left == 5)\\n\\t\\t{\\n\\t\\t\\t*out++ = value;\\n\\t\\t\\tleft--;\\n\\t\\t}\\n\\t\\telse if (value == *in)\\n\\t\\t{\\n\\t\\t\\tin++;\\n\\n\\t\\t\\tif (*in < 0xFF)\\n\\t\\t\\t{\\n\\t\\t\\t\\tlen = (UINT32) * in++;\\n\\t\\t\\t\\tlen += 2;\\n\\t\\t\\t}\\n\\t\\t\\telse\\n\\t\\t\\t{\\n\\t\\t\\t\\tin++;\\n\\t\\t\\t\\tlen = *((UINT32*) in);\\n\\t\\t\\t\\tin += 4;\\n\\t\\t\\t}\\n\\n\\t\\t\\tFillMemory(out, len, value);\\n\\t\\t\\tout += len;\\n\\t\\t\\tleft -= len;\\n\\t\\t}\\n\\t\\telse\\n\\t\\t{\\n\\t\\t\\t*out++ = value;\\n\\t\\t\\tleft--;\\n\\t\\t}\\n\\t}\\n\\n\\t*((UINT32*)out) = *((UINT32*)in);\\n}\\n', 'patch': [' \\t\\t\\t\\tin += 4;\\n', ' \\t\\t\\t}\\n', ' \\n', ' \\t\\t\\tFillMemory(out, len, value);\\n', ' \\t\\t\\tout += len;\\n', ' \\t\\t\\tleft -= len;\\n', ' \\t\\t}\\n', ' \\t\\telse\\n', ' \\t\\t{\\n', ' \\t\\t\\t*out++ = value;\\n', ' \\t\\t\\tleft--;\\n', ' \\t\\t}\\n', ' \\t}\\n', ' \\n', '-\\t*((UINT32*)out) = *((UINT32*)in);\\n', ' }\\n', ' \\n', '-static void nsc_rle_decompress_data(NSC_CONTEXT* context)\\n', ' {\\n', ' \\tUINT16 i;\\n', ' \\tBYTE* rle;\\n', ' \\tUINT32 planeSize;\\n', ' \\tUINT32 originalSize;\\n', ' \\trle = context->Planes;\\n', ' \\n', ' \\tfor (i = 0; i < 4; i++)\\n'], 'vuln': True}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x in final_dataset:\n",
    "    if x['vuln']:\n",
    "        print(x)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final-dataset.json') as f:\n",
    "    final_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in get_next_graph(after_fn):\n",
    "    errored_graphs = []\n",
    "function_name_to_graph = {}\n",
    "for g in get_next_graph(before_fn):\n",
    "#     print(g)\n",
    "    try:\n",
    "        pgg = pydot.graph_from_dot_data(g)\n",
    "    except Exception as e:\n",
    "        print('Errored', g.split('\\n')[0])\n",
    "        errored_graphs.append((g, e))\n",
    "        continue\n",
    "    for pg in pgg:\n",
    "        ng = nx.nx_pydot.from_pydot(pg)\n",
    "        print('Current Function:', ng.name)\n",
    "        vertices = fuction_name_to_graph[ng.name][0]\n",
    "        new_vertices={}\n",
    "        idx = len(vertices.keys())\n",
    "        all_new_labs = []\n",
    "        for k,v in ng.nodes.items():\n",
    "            lab = v['label'][:-2].split(',')[-1]\n",
    "            all_new_labs.append(lab)\n",
    "            if not check_node_with_label_exists(ng.name, lab):\n",
    "                toks = tokenizer(lab)\n",
    "                vecs = [model[t] for t in toks if t in model.vocab]\n",
    "                node_embedding = np.mean(np.asarray(vecs), axis=0)\n",
    "                vertices[k] = (idx, lab, node_embedding)\n",
    "                new_vertices[k] = (idx, lab, node_embedding)\n",
    "                idx+=1\n",
    "        deleted_vertices = []\n",
    "        for v in vertices:\n",
    "            if v[1] not in all_new_labs:\n",
    "                deleted_vertices.append(v)\n",
    "#         print(vertices)\n",
    "        nv = MAX_NODES\n",
    "        patch_add = np.zeros(shape=(nv,nv))\n",
    "        patch_sub = np.zeros(shape=(nv,nv))\n",
    "        for k, v in new_vertices.items():\n",
    "            for d in deleted_vertices():\n",
    "                replaced=False\n",
    "                for h in final_dataset['patch']:\n",
    "                    if v[1] in h.source and d[1] in h.source:\n",
    "                        patch_add[v[0], d[0]] +=1\n",
    "                        patch_add[d[0], v[0]] +=1\n",
    "                        replace=True\n",
    "            if not replaced:\n",
    "                patch_sub[d[0],MAX_NODE-1] += 1\n",
    "        ast_adj = function_name_to_graph[ng.name][1]\n",
    "        cfg_adj = function_name_to_graph[ng.name][2]\n",
    "        cdg_adj = function_name_to_graph[ng.name][3] \n",
    "        function_name_to_graph[ng.name] = (vertices, ast_adj, cfg_adj, cdg_adj,patch_add, patch_sub)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tse)",
   "language": "python",
   "name": "tse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
