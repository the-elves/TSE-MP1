{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "import pydot\n",
    "import networkx as nx\n",
    "from parse import tokenizer\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from networkx.drawing.nx_pydot import from_pydot\n",
    "import numpy as np\n",
    "\n",
    "MAX_NODES=500\n",
    "\n",
    "after_fn = \"/home/ajinkya/TSE/mp1/joern-parse-output/after/graphs.dot\"\n",
    "\n",
    "def get_next_graph(fn):\n",
    "    graph_lines=[]\n",
    "    with open(fn) as f:\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            if line is None: \n",
    "                break\n",
    "#             if line.startswith('digraph'):\n",
    "#                 line = line.replace(\":\", \"_\").replace('~', \"_\")\n",
    "            if line == \"\\n\":\n",
    "                graph = ''.join(graph_lines)\n",
    "                graph_lines=[]\n",
    "                yield graph\n",
    "            else:\n",
    "                graph_lines.append(line)\n",
    "model = KeyedVectors.load_word2vec_format('w2v.model.txt', binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('function_name_to_graph') as f:\n",
    "    funtion_name_to_graph = pickle.load(f)\n",
    "\n",
    "def check_node_with_label_exist(fname, label):\n",
    "    g = function_name_to_graph[fname]\n",
    "    #iterate over before veritces\n",
    "    for v in g[0]:\n",
    "        if label in v[1]:\n",
    "            return True\n",
    "    return False\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('final-dataset.json') as f:\n",
    "    final_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for graph in get_next_graph(after_fn):\n",
    "    errored_graphs = []\n",
    "function_name_to_graph = {}\n",
    "for g in get_next_graph(before_fn):\n",
    "#     print(g)\n",
    "    try:\n",
    "        pgg = pydot.graph_from_dot_data(g)\n",
    "    except Exception as e:\n",
    "        print('Errored', g.split('\\n')[0])\n",
    "        errored_graphs.append((g, e))\n",
    "        continue\n",
    "    for pg in pgg:\n",
    "        ng = nx.nx_pydot.from_pydot(pg)\n",
    "        print('Current Function:', ng.name)\n",
    "        vertices = fuction_name_to_graph[ng.name][0]\n",
    "        new_vertices={}\n",
    "        idx = len(vertices.keys())\n",
    "        all_new_labs = []\n",
    "        for k,v in ng.nodes.items():\n",
    "            lab = v['label'][:-2].split(',')[-1]\n",
    "            all_new_labs.append(lab)\n",
    "            if not check_node_with_label_exists(ng.name, lab):\n",
    "                toks = tokenizer(lab)\n",
    "                vecs = [model[t] for t in toks if t in model.vocab]\n",
    "                node_embedding = np.mean(np.asarray(vecs), axis=0)\n",
    "                vertices[k] = (idx, lab, node_embedding)\n",
    "                new_vertices[k] = (idx, lab, node_embedding)\n",
    "                idx+=1\n",
    "        deleted_vertices = []\n",
    "        for v in vertices:\n",
    "            if v[1] not in all_new_labs:\n",
    "                deleted_vertices.append(v)\n",
    "#         print(vertices)\n",
    "        nv = MAX_NODES\n",
    "        patch_add = np.zeros(shape=(nv,nv))\n",
    "        patch_sub = np.zeros(shape=(nv,nv))\n",
    "        for k, v in new_vertices.items():\n",
    "            for d in deleted_vertices():\n",
    "                replaced=False\n",
    "                for h in final_dataset['patch']:\n",
    "                    if v[1] in h.source and d[1] in h.source:\n",
    "                        patch_add[v[0], d[0]] +=1\n",
    "                        patch_add[d[0], v[0]] +=1\n",
    "                        replace=True\n",
    "            if not replaced:\n",
    "                patch_sub[d[0],MAX_NODE-1] += 1\n",
    "        ast_adj = function_name_to_graph[ng.name][1]\n",
    "        cfg_adj = function_name_to_graph[ng.name][2]\n",
    "        cdg_adj = function_name_to_graph[ng.name][3] \n",
    "        function_name_to_graph[ng.name] = (vertices, ast_adj, cfg_adj, cdg_adj,patch_add, patch_sub)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tse)",
   "language": "python",
   "name": "tse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
